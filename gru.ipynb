{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOmAS2mSCwmH",
        "outputId": "891df4bf-4d78-4815-d944-88ba3b73a1df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data range: 2018-06-13 18:40:00 â†’ 2018-06-27 23:55:00\n",
            "Created 4086 sequences\n",
            "Training: 2614 sequences\n",
            "Validation: 654 sequences\n",
            "Test: 818 sequences\n",
            "Starting training with validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100 - Train Loss: 0.2010 | Val F1: 0.984 | Val Recall: 0.984 | Val Precision: 0.984\n",
            "Epoch 20/100 - Train Loss: 0.1784 | Val F1: 0.976 | Val Recall: 0.984 | Val Precision: 0.968\n",
            "Epoch 30/100 - Train Loss: 0.1692 | Val F1: 0.984 | Val Recall: 0.984 | Val Precision: 0.984\n",
            " Early stopping at epoch 31\n",
            " Best validation F1: 0.992 at epoch 16\n",
            "Loading best model for testing...\n",
            "\n",
            " Finding optimal threshold...\n",
            " Optimal threshold: 0.30\n",
            "\n",
            "==================================================\n",
            " INSULIN RECOMMENDER FINAL REPORT\n",
            "==================================================\n",
            " Dataset Split: Train 2614 | Val 654 | Test 818\n",
            " Optimal Threshold: 0.30\n",
            " Best Epoch: 16\n",
            "\n",
            " BOLUS DETECTION PERFORMANCE:\n",
            "   Recall:    93.4% (71/76)\n",
            "   Precision: 98.6% (71/72)\n",
            "   F1 Score:  95.9%\n",
            "   False Alarms: 1\n",
            "   Missed Detections: 5\n",
            "   True Negatives: 741\n",
            "\n",
            " DOSING ACCURACY:\n",
            "   Basal Rate MAE: 0.1839\n",
            "   Bolus Amount MAE: 0.016\n",
            "   Bolus MAE (Correct Detections): 0.005 (71 events)\n",
            "   RÂ² (Basal): 0.087\n",
            "\n",
            " CONFUSION MATRIX:\n",
            "               Predicted\n",
            "               No Bolus   Bolus\n",
            "Actual No Bolus   741         1\n",
            "Actual Bolus        5        71\n",
            "\n",
            "==================================================\n",
            " RECOMMENDATION EXAMPLES\n",
            "==================================================\n",
            "\n",
            " Example 1 - High Glucose with Carbs:\n",
            "   Glucose: 220, Carbs: 30\n",
            "   â†’ Basal Insulin: 0.001 units\n",
            "   â†’ Bolus Insulin: 1.603 units\n",
            "   â†’ Bolus Recommended: True (confidence: 1.00)\n",
            "\n",
            " Example 2 - Normal Glucose, No Carbs:\n",
            "   Glucose: 110, Carbs: 0\n",
            "   â†’ Basal Insulin: 0.046 units\n",
            "   â†’ Bolus Insulin: 1.572 units\n",
            "   â†’ Bolus Recommended: False (confidence: 0.01)\n",
            "\n",
            " Example 3 - Borderline Case:\n",
            "   Glucose: 180, Carbs: 15\n",
            "   â†’ Basal Insulin: 0.009 units\n",
            "   â†’ Bolus Insulin: 1.577 units\n",
            "   â†’ Bolus Recommended: True (confidence: 1.00)\n",
            "\n",
            "==================================================\n",
            " MODEL TRAINING COMPLETE!\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# ===============================\n",
        "# ðŸ§  GRU-Based Insulin Recommender\n",
        "# ===============================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
        "from sklearn.metrics import recall_score, precision_score, mean_absolute_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "\n",
        "# ------------------------------\n",
        "# âš™ï¸ 1. Read and preprocess data\n",
        "# ------------------------------\n",
        "def read_csv_data(filepath):\n",
        "    df = pd.read_csv(filepath, sep=';')\n",
        "    df.columns = df.columns.str.strip()\n",
        "\n",
        "    df['time'] = pd.to_datetime(df['time'])\n",
        "    df = df.sort_values('time').reset_index(drop=True)\n",
        "\n",
        "    print(f\"Data range: {df['time'].min()} â†’ {df['time'].max()}\")\n",
        "    return df\n",
        "\n",
        "# Replace path with your file\n",
        "df = read_csv_data(\"HUPA0001P.csv\")\n",
        "\n",
        "# ------------------------------\n",
        "# ðŸ”¢ 2. Feature scaling\n",
        "# ------------------------------\n",
        "feature_cols = ['glucose', 'calories', 'heart_rate', 'steps', 'carb_input']\n",
        "target_cols = ['basal_rate', 'bolus_volume_delivered']\n",
        "\n",
        "# Scale inputs\n",
        "scaler_X = MinMaxScaler()\n",
        "df[feature_cols] = scaler_X.fit_transform(df[feature_cols])\n",
        "\n",
        "# Scale basal normally\n",
        "scaler_basal = MinMaxScaler()\n",
        "df['basal_rate'] = scaler_basal.fit_transform(df[['basal_rate']])\n",
        "\n",
        "# Scale bolus only on nonzero values (avoid all squashed zeros)\n",
        "scaler_bolus = RobustScaler()\n",
        "nonzero = df['bolus_volume_delivered'] > 0\n",
        "if nonzero.any():\n",
        "    df.loc[nonzero, 'bolus_volume_delivered'] = scaler_bolus.fit_transform(df.loc[nonzero, ['bolus_volume_delivered']])\n",
        "else:\n",
        "    df['bolus_volume_delivered'] = 0.0\n",
        "\n",
        "# ------------------------------\n",
        "# ðŸª„ 3. Sequence creation\n",
        "# ------------------------------\n",
        "sequence_length = 10\n",
        "\n",
        "def create_sequences(data, seq_len=10):\n",
        "    X, y_basal, y_bolus, y_detect = [], [], [], []\n",
        "    for i in range(len(data) - seq_len):\n",
        "        seq_x = data[feature_cols].iloc[i:i+seq_len].values\n",
        "        seq_y_basal = data['basal_rate'].iloc[i+seq_len]\n",
        "        seq_y_bolus = data['bolus_volume_delivered'].iloc[i+seq_len]\n",
        "        # label 1 if any bolus in window\n",
        "        detect_label = 1.0 if data['bolus_volume_delivered'].iloc[i:i+seq_len].max() > 0 else 0.0\n",
        "\n",
        "        X.append(seq_x)\n",
        "        y_basal.append(seq_y_basal)\n",
        "        y_bolus.append(seq_y_bolus)\n",
        "        y_detect.append(detect_label)\n",
        "    return np.array(X), np.array(y_basal), np.array(y_bolus), np.array(y_detect)\n",
        "\n",
        "X, y_basal, y_bolus, y_detect = create_sequences(df, sequence_length)\n",
        "print(f\"Created {len(X)} sequences\")\n",
        "\n",
        "# ------------------------------\n",
        "# âš–ï¸ 4. PROPER Train-Validation-Test Split\n",
        "# ------------------------------\n",
        "\n",
        "# First split: 80% train+val, 20% test\n",
        "X_temp, X_test, yb_temp, yb_test, yob_temp, yob_test, yd_temp, yd_test = train_test_split(\n",
        "    X, y_basal, y_bolus, y_detect, test_size=0.2, random_state=42, stratify=y_detect\n",
        ")\n",
        "\n",
        "# Second split: 80% of temp for train, 20% for validation (64% train, 16% val, 20% test)\n",
        "X_train, X_val, yb_train, yb_val, yob_train, yob_val, yd_train, yd_val = train_test_split(\n",
        "    X_temp, yb_temp, yob_temp, yd_temp, test_size=0.2, random_state=42, stratify=yd_temp\n",
        ")\n",
        "\n",
        "print(f\"Training: {len(X_train)} sequences\")\n",
        "print(f\"Validation: {len(X_val)} sequences\")\n",
        "print(f\"Test: {len(X_test)} sequences\")\n",
        "\n",
        "# Convert to tensors\n",
        "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_val_t = torch.tensor(X_val, dtype=torch.float32)\n",
        "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
        "\n",
        "yb_train_t = torch.tensor(yb_train, dtype=torch.float32).unsqueeze(-1)\n",
        "yob_train_t = torch.tensor(yob_train, dtype=torch.float32).unsqueeze(-1)\n",
        "yd_train_t = torch.tensor(yd_train, dtype=torch.float32).unsqueeze(-1)\n",
        "\n",
        "yb_val_t = torch.tensor(yb_val, dtype=torch.float32).unsqueeze(-1)\n",
        "yob_val_t = torch.tensor(yob_val, dtype=torch.float32).unsqueeze(-1)\n",
        "yd_val_t = torch.tensor(yd_val, dtype=torch.float32).unsqueeze(-1)\n",
        "\n",
        "yb_test_t = torch.tensor(yb_test, dtype=torch.float32).unsqueeze(-1)\n",
        "yob_test_t = torch.tensor(yob_test, dtype=torch.float32).unsqueeze(-1)\n",
        "yd_test_t = torch.tensor(yd_test, dtype=torch.float32).unsqueeze(-1)\n",
        "\n",
        "# Create datasets and loaders\n",
        "train_ds = TensorDataset(X_train_t, yb_train_t, yob_train_t, yd_train_t)\n",
        "val_ds = TensorDataset(X_val_t, yb_val_t, yob_val_t, yd_val_t)\n",
        "test_ds = TensorDataset(X_test_t, yb_test_t, yob_test_t, yd_test_t)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=32)\n",
        "test_loader = DataLoader(test_ds, batch_size=32)\n",
        "\n",
        "# ------------------------------\n",
        "# ðŸ§© 5. GRU model\n",
        "# ------------------------------\n",
        "class InsulinGRU(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size=64, dropout=0.2):\n",
        "        super(InsulinGRU, self).__init__()\n",
        "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True, dropout=dropout)\n",
        "        self.fc_basal = nn.Linear(hidden_size, 1)\n",
        "        self.fc_bolus = nn.Linear(hidden_size, 1)\n",
        "        self.fc_detect = nn.Linear(hidden_size, 1)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, h = self.gru(x)\n",
        "        h = self.dropout(h[-1])\n",
        "        return self.fc_basal(h), self.fc_bolus(h), self.sigmoid(self.fc_detect(h))\n",
        "\n",
        "model = InsulinGRU(len(feature_cols))\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_reg = nn.MSELoss()\n",
        "loss_cls = nn.BCELoss(weight=torch.tensor([3.0]))  # weight for imbalance\n",
        "\n",
        "# ------------------------------\n",
        "# ðŸŽ¯ 6. IMPROVED Training with Validation & Early Stopping\n",
        "# ------------------------------\n",
        "EPOCHS = 100\n",
        "best_val_f1 = 0\n",
        "patience = 15\n",
        "patience_counter = 0\n",
        "training_history = []\n",
        "\n",
        "print(\"Starting training with validation...\")\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for Xb, yb, yob, yd in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        pred_basal, pred_bolus, pred_detect = model(Xb)\n",
        "        loss = (\n",
        "            loss_reg(pred_basal, yb) +\n",
        "            loss_reg(pred_bolus, yob) +\n",
        "            loss_cls(pred_detect, yd)\n",
        "        )\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Validation phase every epoch\n",
        "    model.eval()\n",
        "    val_preds, val_trues = [], []\n",
        "    val_basal_preds, val_basal_trues = [], []\n",
        "    val_bolus_preds, val_bolus_trues = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for Xb, yb, yob, yd in val_loader:\n",
        "            pb, po, pd = model(Xb)\n",
        "            val_preds.extend(pd.cpu().numpy().flatten())\n",
        "            val_trues.extend(yd.cpu().numpy().flatten())\n",
        "            val_basal_preds.extend(pb.cpu().numpy().flatten())\n",
        "            val_basal_trues.extend(yb.cpu().numpy().flatten())\n",
        "            val_bolus_preds.extend(po.cpu().numpy().flatten())\n",
        "            val_bolus_trues.extend(yob.cpu().numpy().flatten())\n",
        "\n",
        "    val_preds = np.array(val_preds)\n",
        "    val_trues = np.array(val_trues)\n",
        "    val_pred_label = (val_preds > 0.5).astype(int)\n",
        "\n",
        "    val_recall = recall_score(val_trues, val_pred_label, zero_division=0)\n",
        "    val_precision = precision_score(val_trues, val_pred_label, zero_division=0)\n",
        "    val_f1 = 2 * (val_precision * val_recall) / (val_precision + val_recall + 1e-9)\n",
        "    val_basal_mae = mean_absolute_error(val_basal_trues, val_basal_preds)\n",
        "\n",
        "    # Store history\n",
        "    training_history.append({\n",
        "        'epoch': epoch,\n",
        "        'train_loss': total_loss/len(train_loader),\n",
        "        'val_f1': val_f1,\n",
        "        'val_recall': val_recall,\n",
        "        'val_precision': val_precision,\n",
        "        'val_basal_mae': val_basal_mae\n",
        "    })\n",
        "\n",
        "    # Print progress every 10 epochs\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch}/{EPOCHS} - Train Loss: {total_loss/len(train_loader):.4f} | \"\n",
        "              f\"Val F1: {val_f1:.3f} | Val Recall: {val_recall:.3f} | Val Precision: {val_precision:.3f}\")\n",
        "\n",
        "    # Early stopping check\n",
        "    if val_f1 > best_val_f1:\n",
        "        best_val_f1 = val_f1\n",
        "        patience_counter = 0\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "        best_epoch = epoch\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "\n",
        "    if patience_counter >= patience and epoch > 30:\n",
        "        print(f\" Early stopping at epoch {epoch}\")\n",
        "        print(f\" Best validation F1: {best_val_f1:.3f} at epoch {best_epoch}\")\n",
        "        break\n",
        "\n",
        "# Load best model for final evaluation\n",
        "print(\"Loading best model for testing...\")\n",
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "\n",
        "# ------------------------------\n",
        "# ðŸ“Š 7. COMPREHENSIVE Evaluation on Test Set\n",
        "# ------------------------------\n",
        "model.eval()\n",
        "y_true, y_pred, y_true_bolus, y_pred_bolus, y_true_basal, y_pred_basal = [], [], [], [], [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for Xb, yb, yob, yd in test_loader:\n",
        "        pb, po, pd = model(Xb)\n",
        "        y_pred.extend(pd.detach().cpu().numpy().flatten())\n",
        "        y_true.extend(yd.detach().cpu().numpy().flatten())\n",
        "        y_pred_bolus.extend(po.detach().cpu().numpy().flatten())\n",
        "        y_true_bolus.extend(yob.detach().cpu().numpy().flatten())\n",
        "        y_pred_basal.extend(pb.detach().cpu().numpy().flatten())\n",
        "        y_true_basal.extend(yb.detach().cpu().numpy().flatten())\n",
        "\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "\n",
        "# Find optimal threshold on validation set\n",
        "print(\"\\n Finding optimal threshold...\")\n",
        "best_threshold = 0.5\n",
        "best_f1 = 0\n",
        "\n",
        "for threshold in np.arange(0.3, 0.7, 0.02):\n",
        "    y_pred_label = (y_pred > threshold).astype(int)\n",
        "    recall = recall_score(y_true, y_pred_label, zero_division=0)\n",
        "    precision = precision_score(y_true, y_pred_label, zero_division=0)\n",
        "    f1 = 2 * (precision * recall) / (precision + recall + 1e-9)\n",
        "\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_threshold = threshold\n",
        "\n",
        "print(f\" Optimal threshold: {best_threshold:.2f}\")\n",
        "\n",
        "# Final evaluation with optimal threshold\n",
        "y_pred_label = (y_pred > best_threshold).astype(int)\n",
        "\n",
        "recall = recall_score(y_true, y_pred_label)\n",
        "precision = precision_score(y_true, y_pred_label)\n",
        "f1 = 2 * (precision * recall) / (precision + recall + 1e-9)\n",
        "mae_basal = mean_absolute_error(y_true_basal, y_pred_basal)\n",
        "mae_bolus = mean_absolute_error(y_true_bolus, y_pred_bolus)\n",
        "r2_basal = r2_score(y_true_basal, y_pred_basal)\n",
        "\n",
        "# Calculate bolus amount accuracy only for correctly detected bolus events\n",
        "correct_detections = (y_pred_label == 1) & (y_true == 1)\n",
        "if correct_detections.any():\n",
        "    bolus_mae_correct = mean_absolute_error(\n",
        "        np.array(y_true_bolus)[correct_detections],\n",
        "        np.array(y_pred_bolus)[correct_detections]\n",
        "    )\n",
        "    bolus_count = correct_detections.sum()\n",
        "else:\n",
        "    bolus_mae_correct = float('nan')\n",
        "    bolus_count = 0\n",
        "\n",
        "# Confusion matrix\n",
        "true_positives = ((y_pred_label == 1) & (y_true == 1)).sum()\n",
        "false_positives = ((y_pred_label == 1) & (y_true == 0)).sum()\n",
        "false_negatives = ((y_pred_label == 0) & (y_true == 1)).sum()\n",
        "true_negatives = ((y_pred_label == 0) & (y_true == 0)).sum()\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\" INSULIN RECOMMENDER FINAL REPORT\")\n",
        "print(\"=\"*50)\n",
        "print(f\" Dataset Split: Train {len(X_train)} | Val {len(X_val)} | Test {len(X_test)}\")\n",
        "print(f\" Optimal Threshold: {best_threshold:.2f}\")\n",
        "print(f\" Best Epoch: {best_epoch}\")\n",
        "print(\"\\n BOLUS DETECTION PERFORMANCE:\")\n",
        "print(f\"   Recall:    {recall*100:.1f}% ({true_positives}/{true_positives + false_negatives})\")\n",
        "print(f\"   Precision: {precision*100:.1f}% ({true_positives}/{true_positives + false_positives})\")\n",
        "print(f\"   F1 Score:  {f1*100:.1f}%\")\n",
        "print(f\"   False Alarms: {false_positives}\")\n",
        "print(f\"   Missed Detections: {false_negatives}\")\n",
        "print(f\"   True Negatives: {true_negatives}\")\n",
        "\n",
        "print(\"\\n DOSING ACCURACY:\")\n",
        "print(f\"   Basal Rate MAE: {mae_basal:.4f}\")\n",
        "print(f\"   Bolus Amount MAE: {mae_bolus:.3f}\")\n",
        "print(f\"   Bolus MAE (Correct Detections): {bolus_mae_correct:.3f} ({bolus_count} events)\")\n",
        "print(f\"   RÂ² (Basal): {r2_basal:.3f}\")\n",
        "\n",
        "print(\"\\n CONFUSION MATRIX:\")\n",
        "print(f\"               Predicted\")\n",
        "print(f\"               No Bolus   Bolus\")\n",
        "print(f\"Actual No Bolus  {true_negatives:4d}      {false_positives:4d}\")\n",
        "print(f\"Actual Bolus     {false_negatives:4d}      {true_positives:4d}\")\n",
        "\n",
        "# ------------------------------\n",
        "#  8. Example recommendation\n",
        "# ------------------------------\n",
        "def recommend_insulin(glucose, carbs, hr=80, steps=0, calories=0):\n",
        "    x = np.array([[glucose, calories, hr, steps, carbs]])\n",
        "    x = scaler_X.transform(x)\n",
        "    seq = np.expand_dims(x.repeat(sequence_length, axis=0), axis=0)\n",
        "    seq_t = torch.tensor(seq, dtype=torch.float32)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pb, po, pd = model(seq_t)\n",
        "    basal = scaler_basal.inverse_transform(pb.numpy())\n",
        "    bolus = scaler_bolus.inverse_transform(po.numpy())\n",
        "    decision = pd.item() > best_threshold\n",
        "\n",
        "    return {\n",
        "        'basal': basal.item(),\n",
        "        'bolus': bolus.item(),\n",
        "        'recommend_bolus': decision,\n",
        "        'confidence': pd.item()\n",
        "    }\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\" RECOMMENDATION EXAMPLES\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Example 1: High glucose with carbs (should recommend bolus)\n",
        "example1 = recommend_insulin(glucose=220, carbs=30)\n",
        "print(f\"\\n Example 1 - High Glucose with Carbs:\")\n",
        "print(f\"   Glucose: 220, Carbs: 30\")\n",
        "print(f\"   â†’ Basal Insulin: {example1['basal']:.3f} units\")\n",
        "print(f\"   â†’ Bolus Insulin: {example1['bolus']:.3f} units\")\n",
        "print(f\"   â†’ Bolus Recommended: {example1['recommend_bolus']} (confidence: {example1['confidence']:.2f})\")\n",
        "\n",
        "# Example 2: Normal glucose, no carbs (should NOT recommend bolus)\n",
        "example2 = recommend_insulin(glucose=110, carbs=0)\n",
        "print(f\"\\n Example 2 - Normal Glucose, No Carbs:\")\n",
        "print(f\"   Glucose: 110, Carbs: 0\")\n",
        "print(f\"   â†’ Basal Insulin: {example2['basal']:.3f} units\")\n",
        "print(f\"   â†’ Bolus Insulin: {example2['bolus']:.3f} units\")\n",
        "print(f\"   â†’ Bolus Recommended: {example2['recommend_bolus']} (confidence: {example2['confidence']:.2f})\")\n",
        "\n",
        "# Example 3: Borderline case\n",
        "example3 = recommend_insulin(glucose=180, carbs=15)\n",
        "print(f\"\\n Example 3 - Borderline Case:\")\n",
        "print(f\"   Glucose: 180, Carbs: 15\")\n",
        "print(f\"   â†’ Basal Insulin: {example3['basal']:.3f} units\")\n",
        "print(f\"   â†’ Bolus Insulin: {example3['bolus']:.3f} units\")\n",
        "print(f\"   â†’ Bolus Recommended: {example3['recommend_bolus']} (confidence: {example3['confidence']:.2f})\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\" MODEL TRAINING COMPLETE!\")\n",
        "print(\"=\"*50)"
      ]
    }
  ]
}